{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357d3fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca27916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'georgian_spellcheck_seq2seq.pt'\n",
    "checkpoint = torch.load(model_path, map_location = device)\n",
    "\n",
    "itos = checkpoint['vocab']['itos']\n",
    "stoi = checkpoint['vocab']['stoi']\n",
    "pad_idx = checkpoint['vocab']['pad_idx']\n",
    "sos_idx = checkpoint['vocab']['sos_idx']\n",
    "eos_idx = checkpoint['vocab']['eos_idx']\n",
    "unk_idx = checkpoint['vocab']['unk_idx']\n",
    "\n",
    "embedding_dim = checkpoint['config']['embedding_dim']\n",
    "hidden_dim = checkpoint['config']['hidden_dim']\n",
    "num_layers = checkpoint['config']['num_layers']\n",
    "dropout = checkpoint['config']['dropout']\n",
    "max_target_len = checkpoint['config']['max_target_len']\n",
    "\n",
    "vocab_size = len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f40624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_word(word, add_eos = True):\n",
    "    x = []\n",
    "    for ch in word:\n",
    "        x.append(stoi.get(ch, unk_idx))\n",
    "    if add_eos:\n",
    "        x.append(eos_idx)\n",
    "    return x\n",
    "\n",
    "def decode_indices(indices):\n",
    "    chars = []\n",
    "    for idx in indices:\n",
    "        if idx == eos_idx or idx == pad_idx:\n",
    "            break\n",
    "        chars.append(itos[idx])\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ccbf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers = 1, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings = vocab_size,\n",
    "            embedding_dim = embedding_dim,\n",
    "            padding_idx = pad_idx\n",
    "        )\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size = embedding_dim,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = num_layers,\n",
    "            batch_first = True,\n",
    "            dropout = dropout if num_layers > 1 else 0.0,\n",
    "            bidirectional = False\n",
    "        )\n",
    "\n",
    "    def forward(self, src, src_lengths):\n",
    "        embedded = self.embedding(src)\n",
    "\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded,\n",
    "            src_lengths.cpu(),\n",
    "            batch_first = True,\n",
    "            enforce_sorted = False\n",
    "        )\n",
    "\n",
    "        outputs, hidden = self.gru(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first = True)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f51b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, src_lengths):\n",
    "        batch, src_len, hidden_dim = encoder_outputs.size()\n",
    "\n",
    "        query = hidden[-1]\n",
    "\n",
    "        scores = torch.bmm(\n",
    "            encoder_outputs,\n",
    "            query.unsqueeze(2),\n",
    "        ).squeeze(2)\n",
    "\n",
    "        device_scores = scores.device\n",
    "        mask = torch.arange(src_len, device = device_scores).unsqueeze(0) >= src_lengths.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask, float('-inf'))\n",
    "\n",
    "        attn_weights = torch.softmax(scores, dim = 1)\n",
    "\n",
    "        context = torch.bmm(\n",
    "            attn_weights.unsqueeze(1),\n",
    "            encoder_outputs,\n",
    "        ).squeeze(1)\n",
    "\n",
    "        return context, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e9e3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers = 1, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings = vocab_size,\n",
    "            embedding_dim = embedding_dim,\n",
    "            padding_idx = pad_idx\n",
    "        )\n",
    "\n",
    "        self.attention = Attention(hidden_dim)\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size = embedding_dim + hidden_dim,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = num_layers,\n",
    "            batch_first = True,\n",
    "            dropout = dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim * 2, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_step, hidden, encoder_outputs, src_lengths):\n",
    "        embedded = self.dropout(self.embedding(input_step))\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "\n",
    "        context, _ = self.attention(hidden, encoder_outputs, src_lengths)\n",
    "        context = context.unsqueeze(1)\n",
    "\n",
    "        rnn_input = torch.cat([embedded, context], dim = 2)\n",
    "\n",
    "        output, hidden = self.gru(rnn_input, hidden)\n",
    "        output = output.squeeze(1)\n",
    "        context = context.squeeze(1)\n",
    "        concat = torch.cat([output, context], dim = 1)\n",
    "        logits = self.fc_out(concat)\n",
    "\n",
    "        return logits, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af2a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, sos_idx, eos_idx, pad_idx, max_target_len):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sos_idx = sos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.pad_idx = pad_idx\n",
    "        self.max_target_len = max_target_len\n",
    "\n",
    "    def forward(self, src, src_lengths, tgt = None, teacher_forcing_ratio = 0.0):\n",
    "        batch_size = src.size(0)\n",
    "        encoder_outputs, hidden = self.encoder(src, src_lengths)\n",
    "        device_local = src.device\n",
    "\n",
    "        if tgt is not None:\n",
    "            max_len = tgt.size(1)\n",
    "        else:\n",
    "            max_len = self.max_target_len\n",
    "\n",
    "        outputs = torch.zeros(batch_size, max_len, vocab_size, device = device_local)\n",
    "\n",
    "        input_step = torch.full(\n",
    "            (batch_size,),\n",
    "            self.sos_idx,\n",
    "            dtype = torch.long,\n",
    "            device = device_local\n",
    "        )\n",
    "\n",
    "        for t in range(max_len):\n",
    "            logits, hidden = self.decoder(\n",
    "                input_step,\n",
    "                hidden,\n",
    "                encoder_outputs,\n",
    "                src_lengths\n",
    "            )\n",
    "\n",
    "            outputs[:, t, :] = logits\n",
    "            input_step = logits.argmax(dim = 1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f00a3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size, embedding_dim, hidden_dim, num_layers, dropout)\n",
    "decoder = Decoder(vocab_size, embedding_dim, hidden_dim, num_layers, dropout)\n",
    "\n",
    "model = Seq2Seq(\n",
    "    encoder,\n",
    "    decoder,\n",
    "    sos_idx,\n",
    "    eos_idx,\n",
    "    pad_idx,\n",
    "    max_target_len\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print('Model loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91eeb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_word(word, model = model):\n",
    "    src_indices = encode_word(word)\n",
    "    src_tensor = torch.tensor(src_indices, dtype = torch.long).unsqueeze(0).to(device)\n",
    "    src_length = torch.tensor([len(src_indices)], dtype = torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(src_tensor, src_length)\n",
    "\n",
    "    token_indices = logits.argmax(dim = 2)[0].tolist()\n",
    "    return decode_indices(token_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc504230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded words: 23162\n"
     ]
    }
   ],
   "source": [
    "with open('georgian_words.txt', 'r', encoding = 'utf-8') as f:\n",
    "    all_words_list = [w for w in f.read().split(',') if w]\n",
    "\n",
    "print(\"Loaded words:\", len(all_words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c67ff73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "georgian_keyboard_map = [\n",
    "    ['ქ', 'წჭ', 'ე', 'რღ', 'ტთ', 'ყ', 'უ', 'ი', 'ო', 'პ'],\n",
    "    ['ა', 'სშ', 'დ', 'ფ', 'გ', 'ჰ', 'ჯჟ', 'კ', 'ლ', None],\n",
    "    ['ზძ', 'ხ', 'ცჩ', 'ვ', 'ბ', 'ნ', 'მ', None, None, None],\n",
    "]\n",
    "\n",
    "n, m = len(georgian_keyboard_map), len(georgian_keyboard_map[0])\n",
    "\n",
    "dirs = [\n",
    "    (-1, -1), (-1, 0), (-1, 1),\n",
    "    ( 0, -1), ( 0, 0), ( 0, 1),\n",
    "    ( 1, -1), ( 1, 0), ( 1, 1),\n",
    "]\n",
    "\n",
    "step_probabilities = [\n",
    "    0.00005, 0.00020, 0.00005,\n",
    "    0.00020, 0.99900, 0.00020,\n",
    "    0.00005, 0.00200, 0.00005,\n",
    "]\n",
    "\n",
    "def keyboard_typo(word, shift_change_prob = 0.05):\n",
    "    char_to_pos = {}\n",
    "    for i, row in enumerate(georgian_keyboard_map):\n",
    "        for j, cell in enumerate(row):\n",
    "            if cell is not None:\n",
    "                for shift_idx, ch in enumerate(cell):\n",
    "                    char_to_pos[ch] = (i, j, shift_idx)\n",
    "    out = []\n",
    "    for ch in word:\n",
    "        if ch not in char_to_pos:\n",
    "            out.append(ch)\n",
    "            continue\n",
    "        row, col, shift_idx = char_to_pos[ch]\n",
    "        idx = random.choices(range(len(dirs)), weights = step_probabilities)[0]\n",
    "        dr, dc = dirs[idx]\n",
    "        nr, nc = row + dr, col + dc\n",
    "        if 0 <= nr < n and 0 <= nc < m:\n",
    "            target_cell = georgian_keyboard_map[nr][nc]\n",
    "            if target_cell is None:\n",
    "                continue\n",
    "            if random.random() < shift_change_prob and len(target_cell) > 1:\n",
    "                ns = 1 - shift_idx if shift_idx < 2 else 0\n",
    "                ns = min(ns, len(target_cell) - 1)\n",
    "            else:\n",
    "                ns = min(shift_idx, len(target_cell) - 1)\n",
    "            out.append(target_cell[ns])\n",
    "        else:\n",
    "            out.append(ch)\n",
    "    return ''.join(out)\n",
    "\n",
    "def swap_adjacent_chars(word, swap_prob = 0.005):\n",
    "    chars = list(word)\n",
    "    p = swap_prob\n",
    "    i = 0\n",
    "    while i < len(chars) - 1:\n",
    "        if random.random() < p:\n",
    "            chars[i], chars[i + 1] = chars[i + 1], chars[i]\n",
    "            p /= 10\n",
    "            i += 2\n",
    "        else:\n",
    "            i += 1\n",
    "    return ''.join(chars)\n",
    "\n",
    "def double_char(word, double_prob = 0.005):\n",
    "    out = []\n",
    "    p = double_prob\n",
    "    for ch in word:\n",
    "        out.append(ch)\n",
    "        if random.random() < p:\n",
    "            out.append(ch)\n",
    "            p /= 10\n",
    "    return ''.join(out)\n",
    "\n",
    "def corrupt_word(word):\n",
    "    w = keyboard_typo(word)\n",
    "    w = swap_adjacent_chars(w)\n",
    "    w = double_char(w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feffb8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "sample_words = random.sample(all_words_list, 1000)\n",
    "\n",
    "results = []\n",
    "\n",
    "def edit_distance(a, b):\n",
    "    n, m = len(a), len(b)\n",
    "    dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "    for i in range(n + 1): dp[i][0] = i\n",
    "    for j in range(m + 1): dp[0][j] = j\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            if a[i - 1] == b[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n",
    "    return dp[n][m]\n",
    "\n",
    "for word in sample_words:\n",
    "    corrupted = corrupt_word(word)\n",
    "    corrected = correct_word(corrupted)\n",
    "    results.append((word, corrupted, corrected))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46588ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character accuracy: 0.9754837158995313\n",
      "Word accuracy: 0.913\n",
      "Average edit distance: 0.14\n"
     ]
    }
   ],
   "source": [
    "char_total = 0\n",
    "char_correct = 0\n",
    "\n",
    "word_total = 0\n",
    "word_correct = 0\n",
    "\n",
    "edit_sum = 0\n",
    "\n",
    "for gold, corrupted, predicted in results:\n",
    "    for c1, c2 in zip(gold, predicted):\n",
    "        char_total += 1\n",
    "        if c1 == c2:\n",
    "            char_correct += 1\n",
    "\n",
    "    word_total += 1\n",
    "    if gold == predicted:\n",
    "        word_correct += 1\n",
    "\n",
    "    edit_sum += edit_distance(gold, predicted)\n",
    "\n",
    "char_acc = char_correct / max(char_total, 1)\n",
    "word_acc = word_correct / word_total\n",
    "edit_avg = edit_sum / word_total\n",
    "\n",
    "print('Character accuracy:', char_acc)\n",
    "print('Word accuracy:', word_acc)\n",
    "print('Average edit distance:', edit_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print('აალაპარაკდ' in all_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e764814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly fixed words:\n",
      "\n",
      "ეედავება -> ედავება | real_world: ედავება\n",
      "გააფთღებით -> გააფთრებით | real_world: გააფთრებით\n",
      "შშეუხრია -> შეუხრია | real_world: შეუხრია\n",
      "იჭრთ -> ჭირთ | real_world: ჭირთ\n",
      "მოსამშახურეთზ -> მოსამსახურეთა | real_world: მოსამსახურეთა\n",
      "გლეეხის -> გლეხის | real_world: გლეხის\n",
      "ტვალიანი -> თვალიანი | real_world: თვალიანი\n",
      "ფხიძლად -> ფხიზლად | real_world: ფხიზლად\n",
      "წყალთაშა -> წყალთასა | real_world: წყალთასა\n",
      "ზღარტანი -> ზღართანი | real_world: ზღართანი\n",
      "განმსაძღვრელ -> განმსაზღვრელ | real_world: განმსაზღვრელ\n",
      "წყოობილებას -> წყობილებას | real_world: წყობილებას\n",
      "ჩატვლით -> ჩათვლით | real_world: ჩათვლით\n",
      "ნივთშ -> ნივთს | real_world: ნივთს\n",
      "სასჯელიშ -> სასჯელის | real_world: სასჯელის\n",
      "ეშარიგა -> შეარიგა | real_world: შეარიგა\n",
      "მოუნდესს -> მოუნდეს | real_world: მოუნდეს\n",
      "გასაზფდელად -> გასაზრდელად | real_world: გასაზრდელად\n",
      "ემასლაატებოდა -> ემასლაათებოდა | real_world: ემასლაათებოდა\n",
      "ბოსნიუღი -> ბოსნიური | real_world: ბოსნიური\n",
      "არათანნმიმდევრულად -> არათანმიმდევრულად | real_world: არათანმიმდევრულად\n",
      "მოხსენიებიშ -> მოხსენიების | real_world: მოხსენიების\n",
      "გგაიარეთ -> გაიარეთ | real_world: გაიარეთ\n",
      "წელიჭადსა -> წელიწადსა | real_world: წელიწადსა\n",
      "გამრავლებბისას -> გამრავლებისას | real_world: გამრავლებისას\n",
      "დაუდასთურა -> დაუდასტურა | real_world: დაუდასტურა\n",
      "გძებით -> გზებით | real_world: გზებით\n",
      "აკრედტიირებული -> აკრედიტირებული | real_world: აკრედიტირებული\n",
      "ვაღსკვლავები -> ვარსკვლავები | real_world: ვარსკვლავები\n",
      "არსადგენად -> აღსადგენად | real_world: აღსადგენად\n",
      "შტოკ -> სტოკ | real_world: სტოკ\n",
      "გაგრძწლდა -> გაგრძელდა | real_world: გაგრძელდა\n",
      "უსაფრთხოებაძე -> უსაფრთხოებაზე | real_world: უსაფრთხოებაზე\n",
      "ხსივებმა -> სხივებმა | real_world: სხივებმა\n",
      "იუდეასი -> იუდეაში | real_world: იუდეაში\n",
      "იივარგებდა -> ივარგებდა | real_world: ივარგებდა\n",
      "იოღკის -> იორკის | real_world: იორკის\n",
      "ხარვეზებიშ -> ხარვეზების | real_world: ხარვეზების\n",
      "უგგზო -> უგზო | real_world: უგზო\n",
      "ხხელობა -> ხელობა | real_world: ხელობა\n",
      "დოგმატიკოში -> დოგმატიკოსი | real_world: დოგმატიკოსი\n",
      "გამოიყენოშ -> გამოიყენოს | real_world: გამოიყენოს\n",
      "უნებარტვო -> უნებართვო | real_world: უნებართვო\n",
      "დამცირბეულად -> დამცირებულად | real_world: დამცირებულად\n",
      "მანდიტ -> მანდით | real_world: მანდით\n",
      "წწარმოდგენას -> წარმოდგენას | real_world: წარმოდგენას\n",
      "ჯორჟო -> ჯორჯო | real_world: ჯორჯო\n",
      "კლებადოობის -> კლებადობის | real_world: კლებადობის\n",
      "ნიგერიასი -> ნიგერიაში | real_world: ნიგერიაში\n",
      "კრიმინალიშ -> კრიმინალის | real_world: კრიმინალის\n",
      "სიმპტომურიი -> სიმპტომური | real_world: სიმპტომური\n",
      "ხანისს -> ხანის | real_world: ხანის\n",
      "ძლევამოშილი -> ძლევამოსილი | real_world: ძლევამოსილი\n",
      "ტურასვილი -> ტურაშვილი | real_world: ტურაშვილი\n",
      "ფოტოარქიივი -> ფოტოარქივი | real_world: ფოტოარქივი\n",
      "ორგანიიზების -> ორგანიზების | real_world: ორგანიზების\n",
      "ეამბოღა -> ეამბორა | real_world: ეამბორა\n",
      "გაზიფიჩირრება -> გაზიფიცირება | real_world: გაზიფიცირება\n",
      "კონუსიშებურ -> კონუსისებურ | real_world: კონუსისებურ\n",
      "რიჩჩმონდი -> რიჩმონდი | real_world: რიჩმონდი\n",
      "საამღებრო -> სამღებრო | real_world: სამღებრო\n",
      "ცივილიზაჩიამ -> ცივილიზაციამ | real_world: ცივილიზაციამ\n",
      "ღარიბტათვის -> ღარიბთათვის | real_world: ღარიბთათვის\n",
      "რისხვიშ -> რისხვის | real_world: რისხვის\n",
      "პატაგგონელს -> პატაგონელს | real_world: პატაგონელს\n",
      "ვალენსიაშ -> ვალენსიას | real_world: ვალენსიას\n",
      "გურიიის -> გურიის | real_world: გურიის\n",
      "ეცდებბა -> ეცდება | real_world: ეცდება\n",
      "მფარველობიგი -> მფარველობითი | real_world: მფარველობითი\n",
      "მამამტილი -> მამამთილი | real_world: მამამთილი\n",
      "მღვდელშ -> მღვდელს | real_world: მღვდელს\n",
      "მექსსიკა -> მექსიკა | real_world: მექსიკა\n",
      "მჭამშ -> მწამს | real_world: მწამს\n",
      "მარცცვლეულის -> მარცვლეულის | real_world: მარცვლეულის\n",
      "მოჭვეულნი -> მოწვეულნი | real_world: მოწვეულნი\n",
      "შენნობებში -> შენობებში | real_world: შენობებში\n",
      "ანასთასიას -> ანასტასიას | real_world: ანასტასიას\n",
      "ნატროშვიილი -> ნატროშვილი | real_world: ნატროშვილი\n",
      "დაპირისპიღებაზე -> დაპირისპირებაზე | real_world: დაპირისპირებაზე\n",
      "თანჯვიშ -> ტანჯვის | real_world: ტანჯვის\n",
      "აღაბუნებრივად -> არაბუნებრივად | real_world: არაბუნებრივად\n",
      "თავწყალდასხმულშა -> თავწყალდასხმულსა | real_world: თავწყალდასხმულსა\n",
      "დაიგზავნნა -> დაიგზავნა | real_world: დაიგზავნა\n",
      "სეაცქეერდებოდა -> შეაცქერდებოდა | real_world: შეაცქერდებოდა\n",
      "მნახველებშ -> მნახველებს | real_world: მნახველებს\n",
      "ვიშურვებდი -> ვისურვებდი | real_world: ვისურვებდი\n",
      "კვარჩი -> კვარცი | real_world: კვარცი\n",
      "აიტაჩებდა -> აიტაცებდა | real_world: აიტაცებდა\n",
      "შათბურის -> სათბურის | real_world: სათბურის\n",
      "დროსაზე -> დროშაზე | real_world: დროშაზე\n",
      "ჯოღების -> ჯორების | real_world: ჯორების\n",
      "ალტეღნატივის -> ალტერნატივის | real_world: ალტერნატივის\n",
      "ვიქტორიიშ -> ვიქტორიის | real_world: ვიქტორიის\n",
      "კოეფიციენთი -> კოეფიციენტი | real_world: კოეფიციენტი\n",
      "ფრტხილობდა -> ფრთხილობდა | real_world: ფრთხილობდა\n",
      "შტკივა -> სტკივა | real_world: სტკივა\n",
      "მეგობაღია -> მეგობარია | real_world: მეგობარია\n",
      "უარყოფიშ -> უარყოფის | real_world: უარყოფის\n",
      "ძღაპრის -> ზღაპრის | real_world: ზღაპრის\n",
      "ხელისუფლებაშ -> ხელისუფლებას | real_world: ხელისუფლებას\n",
      "აჭოვებს -> აწოვებს | real_world: აწოვებს\n",
      "რუდუნბეით -> რუდუნებით | real_world: რუდუნებით\n",
      "განმართა -> განმარტა | real_world: განმარტა\n",
      "მოქმედებებიშ -> მოქმედებების | real_world: მოქმედებების\n",
      "აცრემლებუილ -> აცრემლებული | real_world: აცრემლებული\n",
      "გადამთერება -> გადამტერება | real_world: გადამტერება\n",
      "უმორჩილებშ -> უმორჩილებს | real_world: უმორჩილებს\n",
      "შემოღჩენილ -> შემორჩენილ | real_world: შემორჩენილ\n",
      "დიდმნიშვვნელოვანი -> დიდმნიშვნელოვანი | real_world: დიდმნიშვნელოვანი\n",
      "დამავიიწყებს -> დამავიწყებს | real_world: დამავიწყებს\n",
      "ვქემეხის -> ქვემეხის | real_world: ქვემეხის\n",
      "ჯვაღდაწერილი -> ჯვარდაწერილი | real_world: ჯვარდაწერილი\n",
      "\n",
      "Fixed a total of 112 words\n"
     ]
    }
   ],
   "source": [
    "correct_cnt = 0\n",
    "print('Correctly fixed words:\\n')\n",
    "\n",
    "for real_world, corrupted, predicted in results:\n",
    "    if corrupted != real_world and predicted == real_world:\n",
    "        correct_cnt += 1\n",
    "        print(corrupted, \"->\", predicted, \"| real_world:\", real_world)\n",
    "\n",
    "print()\n",
    "print('Fixed a total of', correct_cnt, 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4354f1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not fixed words:\n",
      "\n",
      "გამოიკვთეოს -> გამოიკვთეოს | real_world: გამოიკვეთოს\n",
      "ბავყოფთ -> ბავყოფთ | real_world: გავყოფთ\n",
      "ააღიანი -> არიანი | real_world: აღაიანი\n",
      "ეხებდოა -> ეხებდოა | real_world: ეხებოდა\n",
      "მოენდისკენ -> მოენდისკენ | real_world: მოედნისკენ\n",
      "შინაარწობრივ -> სინაარწორივ | real_world: შინაარსობრივ\n",
      "ელიოტკ -> ელიოოტ | real_world: ელიოტი\n",
      "მოღვწაეობამ -> მოღვწარებოაა | real_world: მოღვაწეობამ\n",
      "საწთუმალი -> საწთუმალი | real_world: სასთუმალი\n",
      "აღვნშინავთ -> აღვნშინავთ | real_world: აღვნიშნავთ\n",
      "დანბელების -> დანბელების | real_world: დაბნელების\n",
      "ნაბიჭვრაო -> ნაბიჭვრაო | real_world: ნაბიჭვარო\n",
      "სქვალდებულოა -> სქვალდებულოა | real_world: სავალდებულოა\n",
      "სააზუღგეს -> სააზურგეს | real_world: საზურგეს\n",
      "ორლი -> ორლი | real_world: როლი\n",
      "ახლომხდეველი -> ახლომხდეველი | real_world: ახლომხედველი\n",
      "თოდირა -> თოდირა | real_world: თოდრია\n",
      "ბრიტანდთმა -> ბრიტანდთმა | real_world: ბრიტანეთმა\n",
      "ჰერონიი -> ჰერონი | real_world: ჰეროინი\n",
      "თთველმდნენ -> თველმდნენ | real_world: თვლემდნენ\n",
      "ზაავთებული -> ზავთებული | real_world: აზავთებული\n",
      "გსრუდა -> გარუდა | real_world: გსურდა\n",
      "ქურზაუღს -> ქურძაურს | real_world: აურზაურს\n",
      "დაეამტება -> დაექმატება | real_world: დაემატება\n",
      "ბოობოხიზე -> ბობოხიზე | real_world: ბობოხიძე\n",
      "ლუქსმებურგი -> ლუქსმებურგი | real_world: ლუქსემბურგი\n",
      "დაუნაიწლებია -> დაუნაიწლებია | real_world: დაუნაწილებია\n",
      "აამეყტველა -> ამეყთველა | real_world: აამეტყველა\n",
      "მთოვლის -> მთოვლის | real_world: მოთვლის\n",
      "არსასრულებლად -> არსასრულებლად | real_world: აღსასრულებლად\n",
      "ტუინკის -> ტუინკის | real_world: ტუნიკის\n",
      "ტასისა -> ტასისა | real_world: თასისა\n",
      "ზეცმეტია -> ზეცმეტია | real_world: ზედმეტია\n",
      "შეუთავსებლობსი -> შეუთავსებლობში | real_world: შეუთავსებლობის\n",
      "ამიერკავკაშისი -> ამიერკავკაშისი | real_world: ამიერკავკასიის\n",
      "თრაგიკული -> თრაგიკული | real_world: ტრაგიკული\n",
      "ემიგარნტების -> ემიგარნტების | real_world: ემიგრანტების\n",
      "პრდოიუსერიშ -> პრდოიუსერის | real_world: პროდიუსერის\n",
      "მასპიძნლობის -> მასპიზნლობის | real_world: მასპინძლობის\n",
      "იგნლისუღიდან -> იგნეისურიდან | real_world: ინგლისურიდან\n",
      "მხაერსაა -> მხარესსა | real_world: მხარესაა\n",
      "მეტააფორაა -> მეტაფორა | real_world: მეტაფორაა\n",
      "ჩრეჩილლის -> ჩრეცილის | real_world: ჩერჩილის\n",
      "ზმძუვნებლუი -> ძმძუვნებლლი | real_world: ამძუვნებული\n",
      "პრაქტიკითსვის -> პრაქტიკითსვის | real_world: პრაქტიკისთვის\n",
      "ნიოირ -> ნიოიი | real_world: ნიორი\n",
      "ხთზულების -> ხთაულების | real_world: თხზულების\n",
      "შეყეარა -> შეყეარა | real_world: შეეყარა\n",
      "მრაწუხები -> მრაწუხები | real_world: მარწუხები\n",
      "ანზაური -> ნაზაური | real_world: აზნაური\n",
      "გამოაზრო -> გამოაზრო | real_world: გამოაძრო\n",
      "მაძღროვა -> მაძღროვა | real_world: მაძღრობა\n",
      "თავაურებლად -> თავაურებლად | real_world: თავაუღებლად\n",
      "არაფრესაც -> არაფრესაც | real_world: არაფერსაც\n",
      "ივანეივშილი -> ივანეიივილი | real_world: ივანეიშვილი\n",
      "Couldn't fix a total of 55 words\n"
     ]
    }
   ],
   "source": [
    "incorrect_cnt = 0\n",
    "print('Not fixed words:\\n')\n",
    "\n",
    "for real_world, corrupted, predicted in results:\n",
    "    if corrupted != real_world and predicted != real_world:\n",
    "        incorrect_cnt += 1\n",
    "        print(corrupted, \"->\", predicted, \"| real_world:\", real_world)\n",
    "\n",
    "print('Couldn\\'t fix a total of', incorrect_cnt, 'words')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
